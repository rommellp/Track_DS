{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#import modules for analyzing ,plotting, and formatting\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import datetime\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "t0wktXHAJJ6v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_800_1600 = pd.read_csv(\"merged_800m_1600m_df.csv\")"
      ],
      "metadata": {
        "id": "mikBp-p3JP0I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kNKRqyjtDsRp"
      },
      "outputs": [],
      "source": [
        "#import sklearn and relevant packages\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#separate datasets for the model\n",
        "#here the model is split 67/33\n",
        "m800_1600_train, m800_1600_test = train_test_split(merged_800_1600, test_size=0.33, random_state=0)\n",
        "\n",
        "#gl means grade level\n",
        "#for this model we will use 800/1600m times and grade level\n",
        "gl_800_1600_train = m800_1600_train[['800 Meters', '1600 Meters', 'Grade Level']]\n",
        "gl_800_1600_test = m800_1600_test[['800 Meters', '1600 Meters', 'Grade Level']]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here we separate the features and labels. The features used are the 800m times as well as the grade leve\n",
        "# this calls for dropping the 1600m column for the features df\n",
        "#next I select only the 1600m column for the label df\n",
        "features_800_train = gl_800_1600_train.drop('1600 Meters', axis=1)\n",
        "label_train = gl_800_1600_train['1600 Meters'].copy()\n",
        "\n",
        "#same steps are repeated for the test df\n",
        "features_800_test = gl_800_1600_test.drop('1600 Meters', axis=1)\n",
        "label_test = gl_800_1600_test['1600 Meters'].copy()"
      ],
      "metadata": {
        "id": "X27bKDAxDyoa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_800_train[features_800_train['Grade Level'] == '9th Grade']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "Ym8jGskOD2pW",
        "outputId": "d4aac4cf-a0c3-4215-9ffd-8dd426b16a40"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    800 Meters Grade Level\n",
              "90      139.81   9th Grade\n",
              "38      178.70   9th Grade\n",
              "52      132.60   9th Grade\n",
              "31      153.90   9th Grade\n",
              "32      122.60   9th Grade\n",
              "73      141.42   9th Grade\n",
              "20      131.40   9th Grade\n",
              "65      147.90   9th Grade\n",
              "67      155.90   9th Grade"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13e9b793-272a-4f36-9b9f-c4e675a19b16\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>800 Meters</th>\n",
              "      <th>Grade Level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>139.81</td>\n",
              "      <td>9th Grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>178.70</td>\n",
              "      <td>9th Grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>132.60</td>\n",
              "      <td>9th Grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>153.90</td>\n",
              "      <td>9th Grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>122.60</td>\n",
              "      <td>9th Grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>141.42</td>\n",
              "      <td>9th Grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>131.40</td>\n",
              "      <td>9th Grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>147.90</td>\n",
              "      <td>9th Grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>155.90</td>\n",
              "      <td>9th Grade</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13e9b793-272a-4f36-9b9f-c4e675a19b16')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13e9b793-272a-4f36-9b9f-c4e675a19b16 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13e9b793-272a-4f36-9b9f-c4e675a19b16');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#regression models require numeric data, this means that we have to convert variables from a categorical feature to a binary one.\n",
        "#grade level is converted to 0s and 1s\n",
        "# get dummies turned all non-numeric to numeric.\n",
        "dummy_800_train = pd.get_dummies(features_800_train)\n",
        "\n",
        "#after converting the grade level column, we reindex the df\n",
        "dummy_800_train = dummy_800_train.reindex(columns=dummy_800_train.columns, fill_value=0)\n",
        "features_800_train = dummy_800_train[['800 Meters', 'Grade Level_9th Grade', 'Grade Level_10th Grade', 'Grade Level_11th Grade', 'Grade Level_12th Grade']]\n",
        "features_800_train\n",
        "\n",
        "#the same steps are repeated for the test df\n",
        "dummy_800_test = pd.get_dummies(features_800_test)\n",
        "\n",
        "dummy_800_test = dummy_800_test.reindex(columns=dummy_800_test.columns, fill_value=0)\n",
        "features_800_test = dummy_800_test[['800 Meters' ,'Grade Level_9th Grade' , 'Grade Level_10th Grade', 'Grade Level_11th Grade', 'Grade Level_12th Grade']]\n"
      ],
      "metadata": {
        "id": "yXLwSsyQD3UH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#here I am selecting the runners with times between 59 and 60 seconds in the 800m\n",
        "#next I am finding those same runners in the labeled data (1600m times)\n",
        "#I do this as a simple measure so that I can compare the single test predicitions below, and get \n",
        "# a sense of which model is predicting closes to what we expect a runner to run. \n",
        "\n",
        "times = features_800_train[(features_800_train['800 Meters'] > 121) & (features_800_train['800 Meters'] <= 123)]\n",
        "label_train[times.index].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw9sKLeqD7Xu",
        "outputId": "97ff4085-ac03-4387-a6c7-c3095bbd815c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "291.87199999999996"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I used a small definition from Intro to machine learning to display the scores from the cross val.\n",
        "#this code will be used later to display the scores from cross val cv\n",
        "def display_scores(scores):\n",
        "  print('Scores:', scores)\n",
        "  print('Mean:', scores.mean()),\n",
        "  print('Standard Deviation:', scores.std())\n"
      ],
      "metadata": {
        "id": "O8Noeut1EAau"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have the data processed and formatted to run multiple ML models.\n",
        "These will be LinearRegression, Decision Tree Regression, and Forest Regression.\n",
        "\n",
        "Our main measure of the data is the RMSE. This function compares the values of the labels to the predictions. We compare this value for all the training data and choose a model that works best before we use the test data."
      ],
      "metadata": {
        "id": "ibNcfIZ2Es9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#after preparing the data we are ready to create the linear regression instance\n",
        "# and train the model with out data\n",
        "\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(features_800_train, label_train)\n",
        "\n",
        "#here we are importing another regression model to test the difference,\n",
        "# and checking is a more powerful model will produce better results.\n",
        "#we fit this model and predict on our training data as we did before.\n",
        "\n",
        "tree_reg = DecisionTreeRegressor()\n",
        "tree_reg.fit(features_800_train, label_train)\n",
        "\n",
        "#the most powerful model used in this project\n",
        "forest_reg = RandomForestRegressor()\n",
        "forest_reg.fit(features_800_train, label_train)\n",
        "\n",
        "#we import the one more regression model which will be the most powerful\n",
        "#the steps will be the same as before\n",
        "\n",
        "forest_reg = RandomForestRegressor()\n",
        "forest_reg.fit(features_800_train, label_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ddN2JtflEBOI",
        "outputId": "e55a198a-4aff-4995-f527-819cc9e78877"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After creating an instance for each regression model, we fit each of them on the training data. \n",
        "\n",
        "After each fit we predict on training data and compare the training labels to analyze the accuracy.\n"
      ],
      "metadata": {
        "id": "YQdCmdAME0ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#after training we check out model by predicting using out training data\n",
        "#we compare out predictions on training data vs. the labels and study the difference\n",
        "# RMSE is the Root Mean Square Error, which measures the difference between predicted values and the labels. \n",
        "# this measure is common and works well with regression models.\n",
        "\n",
        "train_pred = linreg.predict(features_800_train)\n",
        "lin_mse = mean_squared_error(label_train, train_pred)\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        "print('linreg RMSE: ', lin_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLCLggI4ExkW",
        "outputId": "640a511c-8d98-4623-ebf2-d926c066f61f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linreg RMSE:  13.348869485902856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting with the Decision Tree Regression \n",
        "tree_pred = tree_reg.predict(features_800_train)\n",
        "tree_mse = mean_squared_error(label_train, tree_pred)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "print('decision tree RMSE: ', tree_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6PZIwOvE4Ba",
        "outputId": "5d5992b6-b4bc-436d-a7fe-62a736cc08d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decision tree RMSE:  1.1789901853462796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction with Forest Regression\n",
        "forest_pred = forest_reg.predict(features_800_train)\n",
        "forest_mse = mean_squared_error(label_train, forest_pred)\n",
        "forest_rmse = np.sqrt(forest_mse)\n",
        "\n",
        "print('forest RMSE:',  forest_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0e2ijTyE6fe",
        "outputId": "f714df5f-2ced-4b97-8f17-4942e119c889"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forest RMSE: 6.382118139663472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here is a small test using a runner with a 60 second 800m.\n",
        "# the number 1 represents a grade level.\n",
        "#using this we can run a simple test to see how acurate a single prediction is.\n",
        "#the array corresponds to 800m time, 9th grade, 10th grade, 11th grade, and 12th grade (in this order).\n",
        "\n",
        "test_arr = np.array([120,0,0,0,1])\n",
        "test_arr = test_arr.reshape(1,-1)\n",
        "\n",
        "#predicting a single result with linreg\n",
        "test_pred_lin = linreg.predict(test_arr)\n",
        "test_pred_lin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqksaA5fE_g1",
        "outputId": "78a9e89b-7399-4d13-dca1-c140657c0930"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([278.32065601])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here we run the same test as before, with a single sample, and compare how the decision tree predicts.\n",
        "#although the decision tree has a lower RMSE than linreg, the prediction is futher off what we would expect.\n",
        "# this shows that the decision tree likely is overfitting the data\n",
        "\n",
        "#predicting a single result with Decison tree\n",
        "test_pred_tree = tree_reg.predict(test_arr)\n",
        "test_pred_tree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLCK49xFFB2g",
        "outputId": "4fd1b701-26e1-47c0-e4dd-5a7011d8270d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([289.74])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting a single result with forest regression \n",
        "test_pred_forest = forest_reg.predict(test_arr)\n",
        "test_pred_forest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDUvMFItFEvY",
        "outputId": "f9a5e36b-65b2-4d72-ad0d-57f2fd87863f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([286.1707])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the same cross val is run using linear regression\n",
        "\n",
        "lin_scores = cross_val_score(linreg, features_800_train, label_train, \n",
        "                         scoring='neg_mean_squared_error', cv=10)\n",
        "\n",
        "#compared to the original linreg, the mean here is marginally better, but it is still insightful to check \n",
        "#the original values and compare.\n",
        "\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8Ugiij6FIpo",
        "outputId": "23ba589b-c99f-4f77-d08f-3b2962c8cf4a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: [13.1911332   9.51272461 27.49774203 19.5148937  10.6467633  14.52670448\n",
            "  8.19557611 15.92691281  8.47523912 14.36145992]\n",
            "Mean: 14.18491492808623\n",
            "Standard Deviation: 5.591338327108107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here I import cross_val_score which will allow me to test the decision tree \n",
        "#and improve how it fits by taking small chunks of the data and training on each chunk\n",
        "# this results in a better fitting.\n",
        "\n",
        "tree_scores = cross_val_score(tree_reg, features_800_train, label_train, \n",
        "                         scoring='neg_mean_squared_error', cv=10)\n",
        "\n",
        "# displaying the scors shows a larger mean\n",
        "#this is expected because before, the data was being overfit\n",
        "tree_rmse_scores = np.sqrt(-tree_scores)\n",
        "display_scores(tree_rmse_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzcIiketFJWj",
        "outputId": "cb502639-7ab1-47a2-bced-6f9ed9dcdc1d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: [11.36338166 18.45760974 32.13726986 20.28521312  5.7044807  10.14720862\n",
            "  8.31305707 19.43924565 13.95037224 13.02975989]\n",
            "Mean: 15.282759856071788\n",
            "Standard Deviation: 7.248185691916131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#just as with the decision tree, randome forest was likely overfitting the training data\n",
        "# when using crossval we see that the mean is a amost twice as bad\n",
        "# still, this model produces the best results\n",
        "#this is also expected because this model is more powerful \n",
        "\n",
        "forest_scores = cross_val_score(forest_reg, features_800_train, label_train, \n",
        "                         scoring='neg_mean_squared_error', cv=10)\n",
        "\n",
        "forest_rmse_scores = np.sqrt(-forest_scores)\n",
        "display_scores(forest_rmse_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s7opHO6FLJj",
        "outputId": "68e5bde6-fac6-4731-becb-0b06759bf5e0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: [ 9.34674714 13.91171746 36.28560061 18.6632799  10.02756969  8.93858707\n",
            "  8.73790153 15.88981465 10.74831101 12.78052592]\n",
            "Mean: 14.53300549908717\n",
            "Standard Deviation: 7.886276452804321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#after going through the models, we import one last package, GridSearchCV\n",
        "#this sorts through many parameters and returns the best one.\n",
        "\n",
        "param_grid = [\n",
        "    {'n_estimators': [3,10,30], 'max_features': [2,4,6,8]},\n",
        "    {'bootstrap': [False], 'n_estimators': [3,10], 'max_features': [2,3,4]}\n",
        "]\n",
        "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "\n",
        "#here the grid search model is used to fit the training data\n",
        "#next we print out the best params and best estimators\n",
        "grid_search.fit(features_800_train, label_train)\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_estimator_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b-IdoKqFLSC",
        "outputId": "0ae90d70-1b1c-46a7-87fe-1290e8cc14b7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_features': 8, 'n_estimators': 10}\n",
            "RandomForestRegressor(max_features=8, n_estimators=10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here the features and estimators are zip together with the scores\n",
        "#then they are printed out so we can see which returned the best and the range of values \n",
        "#that result from the changes in parameters\n",
        "\n",
        "cv_res = grid_search.cv_results_\n",
        "\n",
        "for mean_score, params in zip(cv_res['mean_test_score'], cv_res['params']):\n",
        "  print(np.sqrt(-mean_score), params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9klDlR2FR2p",
        "outputId": "02e6718f-da53-41da-b006-ec7d411330ac"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18.997911535177032 {'max_features': 2, 'n_estimators': 3}\n",
            "18.163856194966648 {'max_features': 2, 'n_estimators': 10}\n",
            "18.5844520646388 {'max_features': 2, 'n_estimators': 30}\n",
            "19.931583877680556 {'max_features': 4, 'n_estimators': 3}\n",
            "18.221927755160422 {'max_features': 4, 'n_estimators': 10}\n",
            "18.09762374961528 {'max_features': 4, 'n_estimators': 30}\n",
            "18.876837276290626 {'max_features': 6, 'n_estimators': 3}\n",
            "16.873477761818148 {'max_features': 6, 'n_estimators': 10}\n",
            "16.506191694105567 {'max_features': 6, 'n_estimators': 30}\n",
            "18.427118202206636 {'max_features': 8, 'n_estimators': 3}\n",
            "16.336630337767243 {'max_features': 8, 'n_estimators': 10}\n",
            "16.718062891182456 {'max_features': 8, 'n_estimators': 30}\n",
            "18.09663891883601 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
            "18.381671073576054 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
            "18.612589326275142 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
            "18.578383552436108 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
            "17.290318137892193 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
            "17.336272341229694 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lastly we isolate the best estimators from the model\n",
        "#we then predict the TEST data and compare to the test labels\n",
        "final_model = grid_search.best_estimator_\n",
        "final_pred = final_model.predict(features_800_test)\n",
        "\n",
        "final_mse = mean_squared_error(label_test, final_pred)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        "print(final_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae6Q0WcxFUHW",
        "outputId": "ee04a7b2-f38f-45c1-bc47-0bd3508ec959"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17.2980286374736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = final_model.predict(test_arr)\n",
        "print(test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhdtlhEQFUrh",
        "outputId": "6f183151-2422-4f2d-d9b6-e18f5eefa2f8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[287.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0nyQTj1hO0_Q"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}